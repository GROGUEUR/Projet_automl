"""
Module principal de l'interface AutoML.

Ce module fournit les fonctions principales fit(), eval() et get_data()
qui constituent l'interface utilisateur du syst√®me AutoML.
"""
from typing import Optional, Dict, Any
import numpy as np

from .data.loader import DataLoader
from .data.preprocessing import DataPreprocessor, train_valid_test_split
from .utils.config import Config
from .evaluation import ModelEvaluator, ResultsVisualizer

# ========== Variables globales pour stocker l'√©tat ==========
_data_loader: Optional[DataLoader] = None
_preprocessor: Optional[DataPreprocessor] = None
_X_train: Optional[np.ndarray] = None
_X_valid: Optional[np.ndarray] = None
_X_test: Optional[np.ndarray] = None
_y_train: Optional[np.ndarray] = None
_y_valid: Optional[np.ndarray] = None
_y_test: Optional[np.ndarray] = None
_task_type: Optional[str] = None
_trained_models: Dict[str, Any] = {}  # Sera utilis√© par Personne 2
_evaluator = None

def fit(data_path: str, **kwargs) -> bool:
    """
    Charge les donn√©es, les pr√©traite et lance l'entra√Ænement.
    Point d'entr√©e principal du syst√®me AutoML.

    Cette fonction:
    1. Charge les donn√©es depuis le chemin sp√©cifi√©
    2. D√©tecte automatiquement le type de t√¢che (classification/r√©gression)
    3. Pr√©traite les donn√©es (gestion des manquantes, normalisation, encodage)
    4. S√©pare les donn√©es en ensembles train/valid/test
    5. Lance l'entra√Ænement des mod√®les (module de Personne 2)

    Args:
        data_path: Chemin vers le r√©pertoire ou fichier de donn√©es
        **kwargs: Arguments suppl√©mentaires pour personnaliser:
            - train_size (float): Proportion pour l'entra√Ænement (d√©faut: 0.7)
            - valid_size (float): Proportion pour la validation (d√©faut: 0.15)
            - test_size (float): Proportion pour le test (d√©faut: 0.15)
            - handle_missing (str): Strat√©gie pour valeurs manquantes (d√©faut: 'mean')
            - scale (bool): Normaliser les features (d√©faut: True)
            - encode_categorical (bool): Encoder les cat√©gorielles (d√©faut: True)
            - random_state (int): Graine al√©atoire (d√©faut: 42)
            - verbose (bool): Afficher les informations (d√©faut: True)

    Returns:
        bool: True si l'ex√©cution s'est bien d√©roul√©e

    Raises:
        FileNotFoundError: Si le chemin de donn√©es n'existe pas
        ValueError: Si les donn√©es sont invalides ou mal format√©es

    Example:
        >>> import automl
        >>> automl.fit(data_path="/path/to/data")
        >>> automl.eval()
    """
    global _data_loader, _preprocessor, _X_train, _X_valid, _X_test
    global _y_train, _y_valid, _y_test, _task_type, _trained_models

    # R√©cup√©rer les param√®tres avec valeurs par d√©faut
    train_size = kwargs.get('train_size', Config.TRAIN_SIZE)
    valid_size = kwargs.get('valid_size', Config.VALID_SIZE)
    test_size = kwargs.get('test_size', Config.TEST_SIZE)
    handle_missing = kwargs.get('handle_missing', Config.HANDLE_MISSING)
    scale = kwargs.get('scale', Config.SCALE_FEATURES)
    encode_categorical = kwargs.get('encode_categorical', Config.ENCODE_CATEGORICAL)
    random_state = kwargs.get('random_state', Config.RANDOM_STATE)
    verbose = kwargs.get('verbose', Config.VERBOSE)

    if verbose:
        print("=" * 60)
        print("AUTOML - SYST√àME D'APPRENTISSAGE AUTOMATIQUE")
        print("=" * 60)
        print()

    # ========== √âTAPE 1: Chargement des donn√©es ==========
    if verbose:
        print("√âTAPE 1/4: Chargement des donn√©es...")
        print(f"  Source: {data_path}")

    try:
        _data_loader = DataLoader(data_path)
        X, y, _task_type = _data_loader.load_data()

        if verbose:
            info = _data_loader.get_info()
            print(f"  ‚úì Donn√©es charg√©es avec succ√®s!")
            print(f"  - Nombre d'√©chantillons: {info['n_samples']}")
            print(f"  - Nombre de features: {info['n_features']}")
            print(f"  - Type de t√¢che: {_task_type}")
            if _task_type == 'classification':
                print(f"  - Nombre de classes: {info['n_classes']}")
            if info['missing_values'] > 0:
                print(f"  - Valeurs manquantes: {info['missing_values']}")
            print()

    except Exception as e:
        print(f"  ‚úó Erreur lors du chargement des donn√©es: {e}")
        raise

    # ========== √âTAPE 2: Pr√©traitement des donn√©es ==========
    if verbose:
        print("√âTAPE 2/4: Pr√©traitement des donn√©es...")
        print(f"  - Gestion des valeurs manquantes: {handle_missing}")
        print(f"  - Normalisation: {scale}")
        print(f"  - Encodage cat√©goriel: {encode_categorical}")

    try:
        _preprocessor = DataPreprocessor(
            handle_missing=handle_missing,
            scale=scale,
            encode_categorical=encode_categorical
        )

        # Fit et transform sur toutes les donn√©es
        X_processed = _preprocessor.fit_transform(X)

        if verbose:
            print(f"  ‚úì Pr√©traitement effectu√© avec succ√®s!")
            print(f"  - Dimensions apr√®s traitement: {X_processed.shape}")
            print()

    except Exception as e:
        print(f"  ‚úó Erreur lors du pr√©traitement: {e}")
        raise

    # ========== √âTAPE 3: S√©paration des donn√©es ==========
    if verbose:
        print("√âTAPE 3/4: S√©paration des donn√©es...")
        print(f"  - Train: {train_size*100:.0f}%")
        print(f"  - Validation: {valid_size*100:.0f}%")
        print(f"  - Test: {test_size*100:.0f}%")

    try:
        splits = train_valid_test_split(
            X_processed, y,
            train_size=train_size,
            valid_size=valid_size,
            test_size=test_size,
            random_state=random_state,
            task_type=_task_type
        )

        _X_train = splits['X_train']
        _X_valid = splits['X_valid']
        _X_test = splits['X_test']
        _y_train = splits['y_train']
        _y_valid = splits['y_valid']
        _y_test = splits['y_test']

        if verbose:
            print(f"  ‚úì Donn√©es s√©par√©es avec succ√®s!")
            print(f"  - Train: {_X_train.shape[0]} √©chantillons")
            print(f"  - Validation: {_X_valid.shape[0]} √©chantillons")
            print(f"  - Test: {_X_test.shape[0]} √©chantillons")
            print()

    except Exception as e:
        print(f"  ‚úó Erreur lors de la s√©paration des donn√©es: {e}")
        raise

    # ========== √âTAPE 4: Entra√Ænement des mod√®les ==========
    if verbose:
        print("√âTAPE 4/4: Entra√Ænement des mod√®les...")

    try:
        # Import du module models (sera cr√©√© par Personne 2)
        # Pour l'instant, on met un placeholder
        try:
            from .models import train_models
            _trained_models = train_models(
                _X_train, _y_train,
                _X_valid, _y_valid,
                _task_type,
                verbose=verbose
            )
            if verbose:
                print(f"  ‚úì {len(_trained_models)} mod√®les entra√Æn√©s avec succ√®s!")
        except ImportError:
            if verbose:
                print("  ‚ö†  Module 'models' non disponible (sera impl√©ment√© par Personne 2)")
                print("  ‚Üí Les donn√©es sont pr√™tes pour l'entra√Ænement!")

        if verbose:
            print()
            print("=" * 60)
            print("SUCC√àS: Pipeline de donn√©es compl√©t√©!")
            print("=" * 60)
            print()

    except Exception as e:
        if verbose:
            print(f"  ‚ö†  Avertissement lors de l'entra√Ænement: {e}")
        # Ne pas lever l'exception pour permettre aux autres modules de se connecter

    return True


def eval(**kwargs) -> Dict[str, Any]:
    """
    √âvalue tous les mod√®les entra√Æn√©s sur les donn√©es de test.
    Point d'entr√©e principal pour l'√©valuation.

    Args:
        **kwargs: Arguments optionnels:
            - verbose (bool): Afficher les d√©tails (d√©faut: True)
            - plot (bool): G√©n√©rer des visualisations (d√©faut: False)

    Returns:
        Dict[str, Any]: R√©sultats d'√©valuation pour tous les mod√®les

    Example:
        >>> import automl
        >>> automl.fit(data_path="/path/to/data")
        >>> results = automl.eval(verbose=True, plot=False)
    """
    global _evaluator, _trained_models, _X_test, _y_test, _X_valid, _y_valid, _task_type

    # 1. V√©rification : A-t-on des mod√®les ?
    if not _trained_models:
        print("‚ö† Aucun mod√®le entra√Æn√©. Appelez fit() d'abord.")
        return {}

    # 2. V√©rification : A-t-on des donn√©es de test ?
    if _X_test is None or _y_test is None:
        print("‚ö† Aucune donn√©e de test disponible. Appelez fit() d'abord.")
        return {}

    # 3. Cr√©er l'√©valuateur
    verbose = kwargs.get('verbose', True)
    _evaluator = ModelEvaluator(verbose=verbose)

    if verbose:
        print("=" * 70)
        print("√âVALUATION DES MOD√àLES")
        print("=" * 70)
        print()

    # 4. Lancer l'√©valuation sur tous les mod√®les
    if verbose:
        print(f"üöÄ √âvaluation de {len(_trained_models)} mod√®le(s) sur l'ensemble de test...")
        print()

    results = _evaluator.evaluate_all(
        _trained_models,
        _X_test, _y_test,
        _X_valid, _y_valid
    )

    # 5. Afficher le tableau comparatif
    if verbose:
        print()
        print("=" * 70)
        print("üìä TABLEAU COMPARATIF DES PERFORMANCES")
        print("=" * 70)
        comparison = _evaluator.get_comparison_table('test')
        if not comparison.empty:
            print(comparison.to_string(index=False))
        else:
            print("Aucun r√©sultat √† afficher")
        print()

    # 6. G√©n√©rer les visualisations si demand√©
    if kwargs.get('plot', False):
        try:
            visualizer = ResultsVisualizer()
            comparison = _evaluator.get_comparison_table('test')
            visualizer.plot_model_comparison(comparison, _task_type)
            if verbose:
                print("‚úì Visualisations g√©n√©r√©es")
        except Exception as e:
            if verbose:
                print(f"‚ö† Erreur lors de la visualisation : {e}")

    return results

def get_evaluator():
    """Retourne l'instance de l'√©valuateur."""
    return _evaluator


def get_data() -> Dict[str, Any]:
    """
    Retourne les donn√©es actuellement charg√©es.

    Utile pour le debugging ou pour acc√©der aux donn√©es depuis
    d'autres modules du syst√®me.

    Returns:
        Dict[str, Any]: Dictionnaire contenant:
            - X_train, X_valid, X_test: Features des diff√©rents ensembles
            - y_train, y_valid, y_test: Targets des diff√©rents ensembles
            - task_type: Type de t√¢che ('classification' ou 'regression')
            - trained_models: Dictionnaire des mod√®les entra√Æn√©s

    Example:
        >>> data = automl.get_data()
        >>> X_train = data['X_train']
        >>> y_train = data['y_train']
    """
    return {
        'X_train': _X_train,
        'X_valid': _X_valid,
        'X_test': _X_test,
        'y_train': _y_train,
        'y_valid': _y_valid,
        'y_test': _y_test,
        'task_type': _task_type,
        'trained_models': _trained_models
    }


def reset() -> None:
    """
    R√©initialise l'√©tat global du syst√®me.

    Utile pour nettoyer la m√©moire ou recommencer avec de nouvelles donn√©es.
    """
    global _data_loader, _preprocessor, _X_train, _X_valid, _X_test
    global _y_train, _y_valid, _y_test, _task_type, _trained_models, _evaluator

    _data_loader = None
    _preprocessor = None
    _X_train = None
    _X_valid = None
    _X_test = None
    _y_train = None
    _y_valid = None
    _y_test = None
    _task_type = None
    _trained_models = {}
    _evaluator = None

    print("‚úì √âtat du syst√®me r√©initialis√©")
