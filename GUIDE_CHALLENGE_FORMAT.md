# Guide d'utilisation avec le format ChallengeMachineLearning

## Format des donn√©es

Le syst√®me AutoML supporte maintenant deux formats de donn√©es :

### Format 1 : Fichier unique (original)
Un seul fichier CSV/TXT avec features + target dans la derni√®re colonne.

```
feature1,feature2,feature3,target
1.0,2.5,A,0
2.0,3.1,B,1
```

### Format 2 : ChallengeMachineLearning (nouveau)
Structure de r√©pertoire avec fichiers s√©par√©s :

```
ChallengeMachineLearning/
‚îî‚îÄ‚îÄ data_A/
    ‚îú‚îÄ‚îÄ data_A.data      # Features (s√©par√©es par espaces)
    ‚îú‚îÄ‚îÄ data_A.solution  # Target (une colonne)
    ‚îî‚îÄ‚îÄ data_A.type      # Type de probl√®me (optionnel)
```

## Utilisation avec le format Challenge

### Exemple simple

```python
import automl

# Pointer vers le r√©pertoire du dataset
automl.fit(data_path="/info/corpus/ChallengeMachineLearning/data_A")

# √âvaluer
automl.eval()
```

### Exemple complet

```python
import automl

# Configuration
DATASET = 'D'  # Changer la lettre ici
BASE_PATH = "/info/corpus/ChallengeMachineLearning"

# Chemin complet
data_path = f"{BASE_PATH}/data_{DATASET}"

# Entra√Ænement
automl.fit(
    data_path=data_path,
    train_size=0.7,
    valid_size=0.15,
    test_size=0.15,
    handle_missing='mean',
    scale=True,
    verbose=True
)

# √âvaluation
results = automl.eval(verbose=True)

# Acc√©der aux r√©sultats
data = automl.get_data()
print(f"Type de t√¢che: {data['task_type']}")
print(f"Nombre de mod√®les: {len(data['trained_models'])}")
```

### Boucle sur plusieurs datasets

```python
import automl

BASE_PATH = "/info/corpus/ChallengeMachineLearning"

# Analyser les datasets A, B, C, D
for dataset_letter in ['A', 'B', 'C', 'D']:
    print(f"\n{'='*60}")
    print(f"DATASET {dataset_letter}")
    print(f"{'='*60}\n")

    # R√©initialiser pour chaque nouveau dataset
    automl.reset()

    # Chemin
    data_path = f"{BASE_PATH}/data_{dataset_letter}"

    try:
        # Entra√Æner
        automl.fit(data_path=data_path, verbose=True)

        # √âvaluer
        results = automl.eval(verbose=True)

        # R√©cup√©rer le meilleur mod√®le
        from automl.models import get_best_model
        best = get_best_model(metric='valid_score')
        print(f"\nüèÜ Meilleur mod√®le: {best.name}")
        print(f"   Score: {best.metadata['valid_score']:.4f}")

    except Exception as e:
        print(f"‚ùå Erreur sur dataset {dataset_letter}: {e}")
```

## D√©tection automatique

Le syst√®me d√©tecte automatiquement :

1. **Format des donn√©es** :
   - Si le r√©pertoire contient `.data` + `.solution` ‚Üí Format Challenge
   - Sinon ‚Üí Format fichier unique

2. **S√©parateur** (pour fichiers .data) :
   - Espaces (par d√©faut pour Challenge)
   - Tabulations, virgules, points-virgules (essay√©s si espaces √©chouent)

3. **Type de t√¢che** :
   - Classification : < 20 valeurs uniques ET < 5% du total
   - R√©gression : sinon

## Tester votre configuration

Utilisez le script de test fourni :

```bash
python test_challenge_format.py
```

Modifiez les variables en haut du script :
- `DATASET = 'D'` ‚Üí Lettre de votre dataset
- `BASE_PATH = "/info/corpus/ChallengeMachineLearning"` ‚Üí Chemin de base

## R√©capitulatif des changements

Le DataLoader a √©t√© modifi√© pour :

‚úÖ D√©tecter automatiquement le format Challenge (`.data` + `.solution`)
‚úÖ Charger les features depuis `data_X.data` (s√©par√©es par espaces)
‚úÖ Charger le target depuis `data_X.solution`
‚úÖ Rester compatible avec l'ancien format (fichier unique)
‚úÖ Ne pas modifier le reste du pipeline (preprocessing, models, evaluation)

## Exemple de structure de fichiers

### data_A.data (extrait)
```
1.0 2.5 3.2 4.1 5.0
2.0 3.1 4.3 5.2 6.1
3.0 1.8 2.9 3.5 4.2
```

### data_A.solution (extrait)
```
0
1
0
```

### Utilisation
```python
import automl

# Pointer vers le r√©pertoire (pas le fichier)
automl.fit(data_path="/info/corpus/ChallengeMachineLearning/data_A")
```

Le syst√®me :
1. D√©tecte qu'il y a `data_A.data` et `data_A.solution`
2. Charge X depuis `.data` (s√©par√© par espaces)
3. Charge y depuis `.solution`
4. Continue normalement avec preprocessing ‚Üí training ‚Üí evaluation

## Comparaison avec votre code original

Votre code :
```python
X = pd.read_csv(data_path / f"data_{dataset_name}.data", sep=' ', header=None)
y = pd.read_csv(data_path / f"data_{dataset_name}.solution", header=None, names=['target'])['target']
```

AutoML maintenant :
```python
automl.fit(data_path=f"{base_path}/data_{dataset_name}")
# Fait exactement la m√™me chose + preprocessing + training + evaluation
```

C'est √©quivalent, mais AutoML ajoute :
- Pr√©traitement automatique
- Entra√Ænement de 6-7 mod√®les
- S√©lection du meilleur
- √âvaluation compl√®te
- M√©triques d√©taill√©es
